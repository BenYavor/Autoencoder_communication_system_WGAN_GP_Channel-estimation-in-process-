{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Compaire.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BenYavor/WGAN_Channel_Estimation-in-process-/blob/master/WGAN_Channel_Estimation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3Mvn1V30ejH",
        "colab_type": "code",
        "outputId": "4349b42e-48b5-4d7c-8d4e-9b8dfa0bc752",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        }
      },
      "source": [
        "!pip install tensorflow==2.0.0\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt   \n",
        "import warnings\n",
        "with warnings.catch_warnings():\n",
        "    warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
        "    import tensorflow as tf\n",
        "import os\n",
        "tf.__version__\n",
        "from tensorflow import keras\n",
        "import time\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import pandas as pd\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import pandas as pd\n",
        "from scipy import special\n",
        "#from Clustering_Equalgrps.equal_groups import EqualGroupsKMeans\n",
        "from tensorflow.keras import layers\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2.0.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.10.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.11.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (2.0.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.8.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.17.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (2.0.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.1.8)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.33.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.2.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.0.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0) (41.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.16.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.7.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0) (2.8.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.3.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.1)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.2.7)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.21.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.7)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2019.9.11)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wlZswcMF7Rt",
        "colab_type": "text"
      },
      "source": [
        "#### Vergleich\n",
        "Als erstes für feste $k$ und $n$, was sich ändert ist die Samplesize, Anzahl der Samples und SNR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qpY-gawAf-9",
        "colab_type": "text"
      },
      "source": [
        "###Systemparameter\n",
        "ACHTUNG: CHANNELANZAHL WURDE UNTERSCHIEDLICH VERWENDET \\\\\n",
        "$k$ - die Anzhal der bits \\\\\n",
        "$M$ - Anzahl der unterschiedlichen Nachrichten \\\\\n",
        "$n$ - channel uses\\\\\n",
        "$N$ - Länge des Rauschvektors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "czeNNfpY1qc2",
        "outputId": "b7320df6-88e4-4476-8634-bda16698b627",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "k = 4      # Number of information bits per message, i.e., M=2**k\n",
        "M = 2**k\n",
        "n = 2    # Number of real channel uses per message\n",
        "#k = int(np.log2(M))\n",
        "#n = 2\n",
        "print(M)\n",
        "\n",
        "batch_size = 100\n",
        "\n",
        "SNR = 7\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BA4TqJBOXXIg",
        "colab_type": "text"
      },
      "source": [
        "## Training Parameter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tb-DiBwSN255",
        "colab_type": "text"
      },
      "source": [
        "### Different Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFMMLrY0LthL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "randN_initial = keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)\n",
        "\n",
        "EncIn = tf.keras.layers.Input(shape=(M,))#, dtype= tf.int32)\n",
        "e1 = tf.keras.layers.Dense(2*n, activation=None)\n",
        "e2 = tf.keras.layers.Lambda(lambda x:tf.reshape(x, shape=[-1,int(n/2),2]))\n",
        "EncOut = tf.keras.layers.Lambda(lambda x: x/tf.sqrt(2*tf.reduce_mean(tf.square(x))))\n",
        "GenIn = tf.keras.layers.Lambda(lambda x:tf.reshape(x,(tf.shape(x)[0],-1)))\n",
        "# = tf.keras.layers.Lambda(generator)\n",
        "DecIn = tf.keras.layers.Lambda(lambda x:tf.reshape(x, shape=[-1,int(n/2),2]))\n",
        "d1 = tf.keras.layers.Lambda(lambda x:tf.reshape(x, shape=[-1,n]))\n",
        "d2 = tf.keras.layers.Dense(M, activation='relu')\n",
        "DecOut = tf.keras.layers.Dense(M, activation='softmax')\n",
        "\n",
        "\n",
        "#noise_std = EbNo_to_noise(TRAINING_SNR)\n",
        "# custom functions / layers without weights\n",
        "norm_layer = keras.layers.Lambda(lambda x: tf.divide(x,tf.sqrt(2*tf.reduce_mean(tf.square(x)))))\n",
        "shape_layer = keras.layers.Lambda(lambda x: tf.reshape(x, shape=[-1,2,n]))\n",
        "shape_layer2 = keras.layers.Lambda(lambda x: tf.reshape(x, shape=[-1,n]))\n",
        "channel_layer = keras.layers.Lambda(lambda x: x + tf.random.normal(tf.shape(x), mean=0.0, stddev=noise_std))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7J96hJhKO9VJ",
        "colab_type": "text"
      },
      "source": [
        "### Help functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uV7pjryDv4M4",
        "colab_type": "code",
        "outputId": "5b3e50f8-4935-4ace-afff-cdd847be97f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "def EbNo2Sigma(ebnodb):\n",
        "    '''Convert Eb/No in dB to noise standard deviation'''\n",
        "    ebno = 10**(ebnodb/10)\n",
        "    return 1/np.sqrt(2*(2*k/n)*ebno)\n",
        "\n",
        "def EbNo_to_noise(ebnodb):\n",
        "    '''Transform EbNo[dB]/snr to noise power'''\n",
        "    ebno = 10**(ebnodb/10)\n",
        "    noise_std = 1/np.sqrt(2*(2*k/n)*ebno) \n",
        "    return noise_std\n",
        "\n",
        "\n",
        "def real_channel(x,noise_std):\n",
        "    # Black-box Channel\n",
        "    #AWGN\n",
        "    return x + tf.random.normal(tf.shape(x), mean=0.0, stddev=noise_std)\n",
        "\n",
        "    #Rayleigh\n",
        "    #return x + tf.sqrt(tf.square(tf.random_normal(tf.shape(x), mean=0.0, stddev=noise_std)) + tf.square(tf.random_normal(tf.shape(x), mean=0.0, stddev=noise_std)))\n",
        "    \n",
        "    #Uniform U(-3;3)    \n",
        "    #return x + tf.random_uniform(tf.shape(x), minval=-2, maxval=2)\n",
        "\n",
        "def B_Ber(input_msg, msg):\n",
        "    '''Calculate the Batch Bit Error Rate'''\n",
        "    pred_error = tf.not_equal(tf.argmax(msg, 1), tf.argmax(input_msg, 1))\n",
        "    bber = tf.reduce_mean(tf.cast(pred_error, tf.float32))\n",
        "    return bber\n",
        "\n",
        "def random_sample(batch_size=32):\n",
        "    msg = np.random.randint(M, size=batch_size)\n",
        "    return msg\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def B_Ber_m(input_msg, msg):\n",
        "    '''Calculate the Batch Bit Error Rate'''\n",
        "    pred_error = tf.not_equal(input_msg, tf.argmax(msg, 1))      \n",
        "    bber = tf.reduce_mean(tf.cast(pred_error, tf.float32))\n",
        "    return bber\n",
        "\n",
        "def SNR_to_noise(snrdb):\n",
        "    '''Transform EbNo[dB]/snr to noise power'''\n",
        "    snr = 10**(snrdb/10)\n",
        "    noise_std = 1/np.sqrt(2*snr)\n",
        "    return noise_std\n",
        "\n",
        "\n",
        "noise_std = EbNo2Sigma(SNR)\n",
        "\n",
        "print(EbNo2Sigma(SNR))\n",
        "print(EbNo_to_noise(SNR))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.15792649852735607\n",
            "0.15792649852735607\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOoYuK_jR9rH",
        "colab_type": "text"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-14T06:31:29.973887Z",
          "start_time": "2019-05-14T06:31:29.969185Z"
        },
        "colab_type": "code",
        "id": "WbqrTgB_SYbf",
        "outputId": "e0027ee0-c693-42c9-8a47-8552beb13594",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "### install necessary packages if in colab\n",
        "def run_subprocess_command(cmd):\n",
        "  process = subprocess.Popen(cmd.split(), stdout=subprocess.PIPE)\n",
        "  for line in process.stdout:\n",
        "      print(line.decode().strip())\n",
        "      \n",
        "import sys, subprocess\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "colab_requirements = ['pip install tf-nightly-gpu-2.0-preview==2.0.0.dev20190513']\n",
        "if IN_COLAB:\n",
        "  for i in colab_requirements:\n",
        "    run_subprocess_command(i)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tf-nightly-gpu-2.0-preview==2.0.0.dev20190513 in /usr/local/lib/python3.6/dist-packages (2.0.0.dev20190513)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview==2.0.0.dev20190513) (1.0.8)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview==2.0.0.dev20190513) (0.2.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview==2.0.0.dev20190513) (1.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview==2.0.0.dev20190513) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview==2.0.0.dev20190513) (0.8.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview==2.0.0.dev20190513) (0.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview==2.0.0.dev20190513) (0.33.6)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview==2.0.0.dev20190513) (1.17.3)\n",
            "Requirement already satisfied: tb-nightly<1.15.0a0,>=1.14.0a0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview==2.0.0.dev20190513) (1.14.0a20190614)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview==2.0.0.dev20190513) (1.12.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview==2.0.0.dev20190513) (0.1.8)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview==2.0.0.dev20190513) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview==2.0.0.dev20190513) (1.11.2)\n",
            "Requirement already satisfied: tensorflow-estimator-2.0-preview in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview==2.0.0.dev20190513) (2.0.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview==2.0.0.dev20190513) (3.10.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tf-nightly-gpu-2.0-preview==2.0.0.dev20190513) (2.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a0,>=1.14.0a0->tf-nightly-gpu-2.0-preview==2.0.0.dev20190513) (41.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a0,>=1.14.0a0->tf-nightly-gpu-2.0-preview==2.0.0.dev20190513) (0.16.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a0,>=1.14.0a0->tf-nightly-gpu-2.0-preview==2.0.0.dev20190513) (3.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3eKFKF5HSYbi"
      },
      "source": [
        "### load packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-14T06:31:30.061880Z",
          "start_time": "2019-05-14T06:31:29.975587Z"
        },
        "colab_type": "code",
        "id": "at1xYevFSYbl",
        "outputId": "59401f19-ffcd-49f5-98d1-5e5f8328ca0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# make visible the only one GPU\n",
        "%env CUDA_VISIBLE_DEVICES=3"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: CUDA_VISIBLE_DEVICES=3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-14T06:31:33.702580Z",
          "start_time": "2019-05-14T06:31:30.063437Z"
        },
        "colab_type": "code",
        "id": "759gzUFlSYbq",
        "outputId": "ad55fadc-0c8a-488f-a92c-cd1a461b82b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.autonotebook import tqdm\n",
        "%matplotlib inline\n",
        "from IPython import display\n",
        "import pandas as pd"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-14T06:31:33.711214Z",
          "start_time": "2019-05-14T06:31:33.706313Z"
        },
        "colab_type": "code",
        "id": "AxY3I4SfSYbt",
        "outputId": "3bbb04f5-ca31-4bb2-b279-f01ea88dba8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0-dev20190513\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-14T06:31:33.803523Z",
          "start_time": "2019-05-14T06:31:33.714599Z"
        },
        "colab_type": "code",
        "id": "Ypym6ZAESYbx",
        "colab": {}
      },
      "source": [
        "#TRAIN_BUF=60000\n",
        "#BATCH_SIZE=512\n",
        "#TEST_BUF=10000\n",
        "#DIMS = (28,28,1)\n",
        "#N_TRAIN_BATCHES =int(TRAIN_BUF/BATCH_SIZE)\n",
        "#N_TEST_BATCHES = int(TEST_BUF/BATCH_SIZE)\n",
        "#print(N_TRAIN_BATCHES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-14T06:31:38.044471Z",
          "start_time": "2019-05-14T06:31:33.805821Z"
        },
        "colab_type": "code",
        "id": "xhqU6sqiSYbz",
        "colab": {}
      },
      "source": [
        "####Datensets muessen theortisch die originale sein, also bei mir Rauschen und das Rauschen über den Kanal\n",
        "\n",
        "# load dataset\n",
        "#(train_images, _), (test_images, _) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# split dataset\n",
        "#train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype(\n",
        "#    \"float32\"\n",
        "#) / 255.0\n",
        "#test_images = test_images.reshape(test_images.shape[0], 28, 28, 1).astype(\"float32\") / 255.0\n",
        "\n",
        "# batch datasets\n",
        "#train_dataset = (\n",
        "#    tf.data.Dataset.from_tensor_slices(train_images)\n",
        "#    .shuffle(TRAIN_BUF)\n",
        "#    .batch(BATCH_SIZE)\n",
        "#)\n",
        "#test_dataset = (\n",
        "#    tf.data.Dataset.from_tensor_slices(test_images)\n",
        "#    .shuffle(TEST_BUF)\n",
        "#    .batch(BATCH_SIZE)\n",
        "#)\n",
        "\n",
        "def creat_train_data(length):\n",
        "  train_dataset=[]\n",
        "  for i in range(length):\n",
        "    x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32) \n",
        "    x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "    train_dataset.append(real_channel(x,noise_std))\n",
        "  return train_dataset\n",
        "\n",
        "train_dataset = creat_train_data(100)\n",
        "\n",
        "test_dataset = creat_train_data(100)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HLxPlL7QSYb1"
      },
      "source": [
        "### Define the network as tf.keras.model object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4gYXZf9hkzY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@tf.function\n",
        "def train(real_data):\n",
        "  gen_gradients, disc_gradients = compute_gradients(real_data)\n",
        "  apply_gradients(gen_gradients, disc_gradients)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPsFbJwchvhq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_gradients(real_data):\n",
        "  \"\"\" passes through the network and computes loss\n",
        "  \"\"\"\n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "    disc_loss, gen_loss = compute_loss(real_data)\n",
        "  gen_gradients = gen_tape.gradient(gen_loss, w_generator.trainable_variables)\n",
        "  disc_gradients = disc_tape.gradient(disc_loss, w_discriminator.trainable_variables)\n",
        "\n",
        "  print(\"compute_gradients\")\n",
        "\n",
        "  return gen_gradients, disc_gradients"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-14T06:31:38.068468Z",
          "start_time": "2019-05-14T06:31:38.046751Z"
        },
        "colab_type": "code",
        "id": "Wyipg-4oSYb1",
        "colab": {}
      },
      "source": [
        "def compute_loss(real_data):\n",
        "  \"\"\" passes through the network and computes loss\n",
        "  \"\"\"\n",
        "        ### pass through network\n",
        "        # generating noise from a uniform distribution\n",
        "  ####Mein noise ist anders als hier\n",
        "  gradient_penalty_weight = 10\n",
        "\n",
        "\n",
        "  \n",
        "  x_samp = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)\n",
        "  #print(x_samp)\n",
        "  # run noise through generator\n",
        "  x_gen = w_generator(x_samp,training =True)     # x_gen zu fake_data\n",
        "  # discriminate x and x_gen\n",
        "  logits_x = w_discriminator(real_data)\n",
        "  logits_x_gen = w_discriminator(x_gen)\n",
        "\n",
        "  # gradient penalty\n",
        "  d_regularizer = gradient_penalty(real_data, x_gen)\n",
        "        ### losses\n",
        "  disc_loss = (tf.reduce_mean(logits_x) - tf.reduce_mean(logits_x_gen)+ d_regularizer * gradient_penalty_weight)\n",
        "\n",
        "        # losses of fake with label \"1\"\n",
        "  gen_loss = tf.reduce_mean(logits_x_gen)\n",
        "  return disc_loss, gen_loss\n",
        "\n",
        "\n",
        "\n",
        "def apply_gradients(gen_gradients, disc_gradients):\n",
        "  gen_optimizer.apply_gradients(zip(gen_gradients, w_generator.trainable_variables))\n",
        "  disc_optimizer.apply_gradients(zip(disc_gradients, w_discriminator.trainable_variables))\n",
        "\n",
        "def gradient_penalty(x, x_gen):\n",
        "  epsilon = tf.random.uniform([x.shape[0], 1, 1, 1], 0.0, 1.0)\n",
        "  x_hat = epsilon * x + (1 - epsilon) * x_gen\n",
        "  with tf.GradientTape() as t:\n",
        "      t.watch(x_hat)\n",
        "      d_hat = w_discriminator(x_hat)\n",
        "  gradients = t.gradient(d_hat, x_hat)\n",
        "  ddx = tf.sqrt(tf.reduce_sum(gradients ** 2, axis=[1, 2]))\n",
        "  d_regularizer = tf.reduce_mean((ddx - 1.0) ** 2)\n",
        "  #print(\"gradient_penalty\")\n",
        "  return d_regularizer\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qEVl58nDSYb4"
      },
      "source": [
        "### Define the network architecture\n",
        "\n",
        "## Changes\n",
        "in dem vorherigen GAN modell hat der discriminator side_infomation erhalten, worin das original Rauschen enthalten war. Dies ist in dem WGAN paper anders gemacht worden."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-14T06:31:38.219862Z",
          "start_time": "2019-05-14T06:31:38.070570Z"
        },
        "colab_type": "code",
        "id": "dyU21SGbSYb4",
        "colab": {}
      },
      "source": [
        "N_Z = n\n",
        "\n",
        "\n",
        "w_generator = keras.models.Sequential([\n",
        "  tf.keras.layers.Input(shape=(n,)),\n",
        "  tf.keras.layers.Dense(32,use_bias=True,  activation='relu'),\n",
        "  tf.keras.layers.Dense(32,use_bias=True, activation='relu'),\n",
        "  tf.keras.layers.Dense(n, use_bias= True, activation='sigmoid')\n",
        "   ])\n",
        "\n",
        "w_discriminator = keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(32,use_bias=True, kernel_initializer=randN_initial,activation='relu',input_shape=((n,))),\n",
        "  #model.add(tf.keras.layers.Dense(32,use_bias=True, kernel_initializer=randN_initial, activation='relu'))\n",
        "  tf.keras.layers.Dense(1,use_bias=False, activation='sigmoid')\n",
        "])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-10T18:40:40.306731Z",
          "start_time": "2019-05-10T18:40:40.292930Z"
        },
        "colab_type": "text",
        "id": "wi_ZuWBdSYb6"
      },
      "source": [
        "### Create Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-14T06:31:39.047233Z",
          "start_time": "2019-05-14T06:31:38.222179Z"
        },
        "colab_type": "code",
        "id": "dSYjNRAwSYb7",
        "colab": {}
      },
      "source": [
        "# optimizers\n",
        "gen_optimizer = tf.keras.optimizers.Adam(0.0001)#, beta_1=0.5)\n",
        "disc_optimizer = tf.keras.optimizers.RMSprop(0.0005)# train the model\n",
        "# model\n",
        "#model = WGAN(\n",
        "#    gen = w_generator,\n",
        "#    disc = w_discriminator,\n",
        "#    gen_optimizer = gen_optimizer,\n",
        "#    disc_optimizer = disc_optimizer,\n",
        "#    n_Z = N_Z,\n",
        "gradient_penalty_weight = 10.0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qwBg8NwrSYb9"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-14T06:31:39.056490Z",
          "start_time": "2019-05-14T06:31:39.049635Z"
        },
        "colab_type": "code",
        "id": "47sz8RMeSYb-",
        "colab": {}
      },
      "source": [
        "# exampled data for plotting results\n",
        "def plot_reconstruction(model, nex=8, zm=2):\n",
        "    samples = model.generate(tf.random.normal(shape=(BATCH_SIZE, N_Z)))\n",
        "    fig, axs = plt.subplots(ncols=nex, nrows=1, figsize=(zm * nex, zm))\n",
        "    for axi in range(nex):\n",
        "        axs[axi].matshow(\n",
        "                    samples.numpy()[axi].squeeze(), cmap=plt.cm.Greys, vmin=0, vmax=1\n",
        "                )\n",
        "        axs[axi].axis('off')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-14T06:31:39.152670Z",
          "start_time": "2019-05-14T06:31:39.058505Z"
        },
        "colab_type": "code",
        "id": "pKkEX9yBSYcB",
        "colab": {}
      },
      "source": [
        "# a pandas dataframe to save the loss information to\n",
        "losses = pd.DataFrame(columns = ['disc_loss', 'gen_loss'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-14T07:04:26.791634Z",
          "start_time": "2019-05-14T07:04:17.126436Z"
        },
        "colab_type": "code",
        "id": "00dI2M4iSYcE",
        "outputId": "113ebd6b-33af-4017-e5c0-e82a5372392b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "n_epochs = 500\n",
        "for epoch in range(n_epochs):\n",
        "  x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32) \n",
        "  x_samp  = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "  real_data = real_channel(x_samp, noise_std)\n",
        "  train(real_data)\n",
        "    # test on holdout\n",
        "  loss = []\n",
        "\n",
        "  loss.append(compute_loss(real_data))\n",
        "  losses.loc[len(losses)] = np.mean(loss, axis=0)\n",
        "  print(\n",
        "       \"Epoch: {} | disc_loss: {} | gen_loss: {}\".format(\n",
        "            epoch, losses.disc_loss.values[-1], losses.gen_loss.values[-1]\n",
        "        )  )\n",
        "# plot_reconstruction(model)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "compute_gradients\n",
            "Epoch: 0 | disc_loss: 7.296729564666748 | gen_loss: 0.5035708546638489\n",
            "compute_gradients\n",
            "Epoch: 1 | disc_loss: 7.239821910858154 | gen_loss: 0.5041967034339905\n",
            "compute_gradients\n",
            "Epoch: 2 | disc_loss: 7.054571628570557 | gen_loss: 0.5047413110733032\n",
            "compute_gradients\n",
            "Epoch: 3 | disc_loss: 6.89886474609375 | gen_loss: 0.5053767561912537\n",
            "compute_gradients\n",
            "Epoch: 4 | disc_loss: 6.6467084884643555 | gen_loss: 0.5056905746459961\n",
            "compute_gradients\n",
            "Epoch: 5 | disc_loss: 6.61902379989624 | gen_loss: 0.5058331489562988\n",
            "compute_gradients\n",
            "Epoch: 6 | disc_loss: 6.489140033721924 | gen_loss: 0.5062851905822754\n",
            "compute_gradients\n",
            "Epoch: 7 | disc_loss: 6.474483013153076 | gen_loss: 0.5065643787384033\n",
            "compute_gradients\n",
            "Epoch: 8 | disc_loss: 6.4216508865356445 | gen_loss: 0.5070045590400696\n",
            "compute_gradients\n",
            "Epoch: 9 | disc_loss: 6.4001970291137695 | gen_loss: 0.5075452327728271\n",
            "compute_gradients\n",
            "Epoch: 10 | disc_loss: 6.216831684112549 | gen_loss: 0.5076703429222107\n",
            "compute_gradients\n",
            "Epoch: 11 | disc_loss: 6.149714946746826 | gen_loss: 0.5080625414848328\n",
            "compute_gradients\n",
            "Epoch: 12 | disc_loss: 6.063474655151367 | gen_loss: 0.5083020925521851\n",
            "compute_gradients\n",
            "Epoch: 13 | disc_loss: 6.103011131286621 | gen_loss: 0.5087577700614929\n",
            "compute_gradients\n",
            "Epoch: 14 | disc_loss: 5.977403163909912 | gen_loss: 0.5090770125389099\n",
            "compute_gradients\n",
            "Epoch: 15 | disc_loss: 5.8449201583862305 | gen_loss: 0.5092988610267639\n",
            "compute_gradients\n",
            "Epoch: 16 | disc_loss: 5.933615684509277 | gen_loss: 0.5097232460975647\n",
            "compute_gradients\n",
            "Epoch: 17 | disc_loss: 5.738532066345215 | gen_loss: 0.5101043581962585\n",
            "compute_gradients\n",
            "Epoch: 18 | disc_loss: 5.535632610321045 | gen_loss: 0.5101161599159241\n",
            "compute_gradients\n",
            "Epoch: 19 | disc_loss: 5.541401386260986 | gen_loss: 0.5106828808784485\n",
            "compute_gradients\n",
            "Epoch: 20 | disc_loss: 5.414083957672119 | gen_loss: 0.511077344417572\n",
            "compute_gradients\n",
            "Epoch: 21 | disc_loss: 5.432320594787598 | gen_loss: 0.5115686655044556\n",
            "compute_gradients\n",
            "Epoch: 22 | disc_loss: 5.333066463470459 | gen_loss: 0.5119351148605347\n",
            "compute_gradients\n",
            "Epoch: 23 | disc_loss: 5.494789123535156 | gen_loss: 0.5120657086372375\n",
            "compute_gradients\n",
            "Epoch: 24 | disc_loss: 5.302519798278809 | gen_loss: 0.5126346945762634\n",
            "compute_gradients\n",
            "Epoch: 25 | disc_loss: 5.391573905944824 | gen_loss: 0.5127934217453003\n",
            "compute_gradients\n",
            "Epoch: 26 | disc_loss: 5.267230033874512 | gen_loss: 0.5133779644966125\n",
            "compute_gradients\n",
            "Epoch: 27 | disc_loss: 5.153436660766602 | gen_loss: 0.5138208866119385\n",
            "compute_gradients\n",
            "Epoch: 28 | disc_loss: 5.098893642425537 | gen_loss: 0.513810396194458\n",
            "compute_gradients\n",
            "Epoch: 29 | disc_loss: 5.033823490142822 | gen_loss: 0.5142489671707153\n",
            "compute_gradients\n",
            "Epoch: 30 | disc_loss: 5.1353325843811035 | gen_loss: 0.514390766620636\n",
            "compute_gradients\n",
            "Epoch: 31 | disc_loss: 4.906617641448975 | gen_loss: 0.5148088335990906\n",
            "compute_gradients\n",
            "Epoch: 32 | disc_loss: 4.996984958648682 | gen_loss: 0.5154945850372314\n",
            "compute_gradients\n",
            "Epoch: 33 | disc_loss: 4.907355785369873 | gen_loss: 0.5155062675476074\n",
            "compute_gradients\n",
            "Epoch: 34 | disc_loss: 4.709153652191162 | gen_loss: 0.5157562494277954\n",
            "compute_gradients\n",
            "Epoch: 35 | disc_loss: 4.768401622772217 | gen_loss: 0.5163437128067017\n",
            "compute_gradients\n",
            "Epoch: 36 | disc_loss: 4.814258575439453 | gen_loss: 0.5166558027267456\n",
            "compute_gradients\n",
            "Epoch: 37 | disc_loss: 4.6711745262146 | gen_loss: 0.5173954963684082\n",
            "compute_gradients\n",
            "Epoch: 38 | disc_loss: 4.575071334838867 | gen_loss: 0.5175445079803467\n",
            "compute_gradients\n",
            "Epoch: 39 | disc_loss: 4.552240371704102 | gen_loss: 0.5177505612373352\n",
            "compute_gradients\n",
            "Epoch: 40 | disc_loss: 4.562375068664551 | gen_loss: 0.5182905793190002\n",
            "compute_gradients\n",
            "Epoch: 41 | disc_loss: 4.3575334548950195 | gen_loss: 0.5187298059463501\n",
            "compute_gradients\n",
            "Epoch: 42 | disc_loss: 4.357028484344482 | gen_loss: 0.519149899482727\n",
            "compute_gradients\n",
            "Epoch: 43 | disc_loss: 4.332024097442627 | gen_loss: 0.5195828676223755\n",
            "compute_gradients\n",
            "Epoch: 44 | disc_loss: 4.2066650390625 | gen_loss: 0.5203549265861511\n",
            "compute_gradients\n",
            "Epoch: 45 | disc_loss: 4.2759175300598145 | gen_loss: 0.5206942558288574\n",
            "compute_gradients\n",
            "Epoch: 46 | disc_loss: 4.184234619140625 | gen_loss: 0.5209850072860718\n",
            "compute_gradients\n",
            "Epoch: 47 | disc_loss: 4.068266868591309 | gen_loss: 0.5218700170516968\n",
            "compute_gradients\n",
            "Epoch: 48 | disc_loss: 3.9946227073669434 | gen_loss: 0.5221767425537109\n",
            "compute_gradients\n",
            "Epoch: 49 | disc_loss: 3.809476137161255 | gen_loss: 0.5225775241851807\n",
            "compute_gradients\n",
            "Epoch: 50 | disc_loss: 4.01047420501709 | gen_loss: 0.523341715335846\n",
            "compute_gradients\n",
            "Epoch: 51 | disc_loss: 3.9886741638183594 | gen_loss: 0.5238894820213318\n",
            "compute_gradients\n",
            "Epoch: 52 | disc_loss: 3.9281656742095947 | gen_loss: 0.5243946313858032\n",
            "compute_gradients\n",
            "Epoch: 53 | disc_loss: 3.8827247619628906 | gen_loss: 0.5246809124946594\n",
            "compute_gradients\n",
            "Epoch: 54 | disc_loss: 3.78961443901062 | gen_loss: 0.5249392986297607\n",
            "compute_gradients\n",
            "Epoch: 55 | disc_loss: 3.4645183086395264 | gen_loss: 0.5250676870346069\n",
            "compute_gradients\n",
            "Epoch: 56 | disc_loss: 3.479348659515381 | gen_loss: 0.5257143378257751\n",
            "compute_gradients\n",
            "Epoch: 57 | disc_loss: 3.439512252807617 | gen_loss: 0.5259301662445068\n",
            "compute_gradients\n",
            "Epoch: 58 | disc_loss: 3.5333149433135986 | gen_loss: 0.5266796350479126\n",
            "compute_gradients\n",
            "Epoch: 59 | disc_loss: 3.4906649589538574 | gen_loss: 0.5271098017692566\n",
            "compute_gradients\n",
            "Epoch: 60 | disc_loss: 3.5622527599334717 | gen_loss: 0.5275735259056091\n",
            "compute_gradients\n",
            "Epoch: 61 | disc_loss: 3.6512644290924072 | gen_loss: 0.5278940796852112\n",
            "compute_gradients\n",
            "Epoch: 62 | disc_loss: 3.3445498943328857 | gen_loss: 0.5283196568489075\n",
            "compute_gradients\n",
            "Epoch: 63 | disc_loss: 3.5017316341400146 | gen_loss: 0.5282350182533264\n",
            "compute_gradients\n",
            "Epoch: 64 | disc_loss: 3.457982063293457 | gen_loss: 0.5293221473693848\n",
            "compute_gradients\n",
            "Epoch: 65 | disc_loss: 3.3549275398254395 | gen_loss: 0.5290258526802063\n",
            "compute_gradients\n",
            "Epoch: 66 | disc_loss: 3.03684401512146 | gen_loss: 0.5293744802474976\n",
            "compute_gradients\n",
            "Epoch: 67 | disc_loss: 2.987247943878174 | gen_loss: 0.5302151441574097\n",
            "compute_gradients\n",
            "Epoch: 68 | disc_loss: 3.0794806480407715 | gen_loss: 0.5309361815452576\n",
            "compute_gradients\n",
            "Epoch: 69 | disc_loss: 3.0030605792999268 | gen_loss: 0.5313168168067932\n",
            "compute_gradients\n",
            "Epoch: 70 | disc_loss: 2.989048480987549 | gen_loss: 0.5318876504898071\n",
            "compute_gradients\n",
            "Epoch: 71 | disc_loss: 3.0112571716308594 | gen_loss: 0.5315768718719482\n",
            "compute_gradients\n",
            "Epoch: 72 | disc_loss: 2.5517024993896484 | gen_loss: 0.5322063565254211\n",
            "compute_gradients\n",
            "Epoch: 73 | disc_loss: 2.877225399017334 | gen_loss: 0.5327506065368652\n",
            "compute_gradients\n",
            "Epoch: 74 | disc_loss: 2.7153286933898926 | gen_loss: 0.5328084230422974\n",
            "compute_gradients\n",
            "Epoch: 75 | disc_loss: 2.8107404708862305 | gen_loss: 0.5342613458633423\n",
            "compute_gradients\n",
            "Epoch: 76 | disc_loss: 2.693186044692993 | gen_loss: 0.5337029695510864\n",
            "compute_gradients\n",
            "Epoch: 77 | disc_loss: 2.6510732173919678 | gen_loss: 0.5345601439476013\n",
            "compute_gradients\n",
            "Epoch: 78 | disc_loss: 2.619346857070923 | gen_loss: 0.5348448157310486\n",
            "compute_gradients\n",
            "Epoch: 79 | disc_loss: 2.5372979640960693 | gen_loss: 0.5354222655296326\n",
            "compute_gradients\n",
            "Epoch: 80 | disc_loss: 2.5269055366516113 | gen_loss: 0.5356430411338806\n",
            "compute_gradients\n",
            "Epoch: 81 | disc_loss: 2.444870948791504 | gen_loss: 0.5360611081123352\n",
            "compute_gradients\n",
            "Epoch: 82 | disc_loss: 2.322439432144165 | gen_loss: 0.5365277528762817\n",
            "compute_gradients\n",
            "Epoch: 83 | disc_loss: 2.3504927158355713 | gen_loss: 0.5370237827301025\n",
            "compute_gradients\n",
            "Epoch: 84 | disc_loss: 2.293503522872925 | gen_loss: 0.5374265909194946\n",
            "compute_gradients\n",
            "Epoch: 85 | disc_loss: 2.296748161315918 | gen_loss: 0.5378220081329346\n",
            "compute_gradients\n",
            "Epoch: 86 | disc_loss: 2.352914810180664 | gen_loss: 0.5380155444145203\n",
            "compute_gradients\n",
            "Epoch: 87 | disc_loss: 2.1729068756103516 | gen_loss: 0.5387358069419861\n",
            "compute_gradients\n",
            "Epoch: 88 | disc_loss: 2.1247260570526123 | gen_loss: 0.539158046245575\n",
            "compute_gradients\n",
            "Epoch: 89 | disc_loss: 1.8047219514846802 | gen_loss: 0.5400475859642029\n",
            "compute_gradients\n",
            "Epoch: 90 | disc_loss: 1.7284760475158691 | gen_loss: 0.5402542352676392\n",
            "compute_gradients\n",
            "Epoch: 91 | disc_loss: 2.0594851970672607 | gen_loss: 0.5405634641647339\n",
            "compute_gradients\n",
            "Epoch: 92 | disc_loss: 2.025362253189087 | gen_loss: 0.5413253307342529\n",
            "compute_gradients\n",
            "Epoch: 93 | disc_loss: 2.0738706588745117 | gen_loss: 0.541408896446228\n",
            "compute_gradients\n",
            "Epoch: 94 | disc_loss: 1.9730499982833862 | gen_loss: 0.5418521761894226\n",
            "compute_gradients\n",
            "Epoch: 95 | disc_loss: 1.8786327838897705 | gen_loss: 0.5423152446746826\n",
            "compute_gradients\n",
            "Epoch: 96 | disc_loss: 1.7582727670669556 | gen_loss: 0.5427161455154419\n",
            "compute_gradients\n",
            "Epoch: 97 | disc_loss: 1.5848735570907593 | gen_loss: 0.5430651307106018\n",
            "compute_gradients\n",
            "Epoch: 98 | disc_loss: 1.4867372512817383 | gen_loss: 0.5435945987701416\n",
            "compute_gradients\n",
            "Epoch: 99 | disc_loss: 1.6082794666290283 | gen_loss: 0.5431313514709473\n",
            "compute_gradients\n",
            "Epoch: 100 | disc_loss: 1.6411547660827637 | gen_loss: 0.5435380339622498\n",
            "compute_gradients\n",
            "Epoch: 101 | disc_loss: 1.7148489952087402 | gen_loss: 0.5442590117454529\n",
            "compute_gradients\n",
            "Epoch: 102 | disc_loss: 1.4638173580169678 | gen_loss: 0.5442570447921753\n",
            "compute_gradients\n",
            "Epoch: 103 | disc_loss: 1.3660147190093994 | gen_loss: 0.5448333024978638\n",
            "compute_gradients\n",
            "Epoch: 104 | disc_loss: 1.4744977951049805 | gen_loss: 0.5447407960891724\n",
            "compute_gradients\n",
            "Epoch: 105 | disc_loss: 1.34299898147583 | gen_loss: 0.5443185567855835\n",
            "compute_gradients\n",
            "Epoch: 106 | disc_loss: 1.5362739562988281 | gen_loss: 0.545479416847229\n",
            "compute_gradients\n",
            "Epoch: 107 | disc_loss: 1.3469932079315186 | gen_loss: 0.545561671257019\n",
            "compute_gradients\n",
            "Epoch: 108 | disc_loss: 1.409111738204956 | gen_loss: 0.5464301109313965\n",
            "compute_gradients\n",
            "Epoch: 109 | disc_loss: 1.3647412061691284 | gen_loss: 0.5463407039642334\n",
            "compute_gradients\n",
            "Epoch: 110 | disc_loss: 1.182958960533142 | gen_loss: 0.5468202829360962\n",
            "compute_gradients\n",
            "Epoch: 111 | disc_loss: 1.273850440979004 | gen_loss: 0.5475412607192993\n",
            "compute_gradients\n",
            "Epoch: 112 | disc_loss: 1.1309878826141357 | gen_loss: 0.5472557544708252\n",
            "compute_gradients\n",
            "Epoch: 113 | disc_loss: 1.0113444328308105 | gen_loss: 0.5477381348609924\n",
            "compute_gradients\n",
            "Epoch: 114 | disc_loss: 0.9261442422866821 | gen_loss: 0.5479390025138855\n",
            "compute_gradients\n",
            "Epoch: 115 | disc_loss: 1.0896018743515015 | gen_loss: 0.5487977862358093\n",
            "compute_gradients\n",
            "Epoch: 116 | disc_loss: 1.0684144496917725 | gen_loss: 0.5486581921577454\n",
            "compute_gradients\n",
            "Epoch: 117 | disc_loss: 1.0064165592193604 | gen_loss: 0.5495460629463196\n",
            "compute_gradients\n",
            "Epoch: 118 | disc_loss: 0.9802160263061523 | gen_loss: 0.549578070640564\n",
            "compute_gradients\n",
            "Epoch: 119 | disc_loss: 1.0101704597473145 | gen_loss: 0.5493742227554321\n",
            "compute_gradients\n",
            "Epoch: 120 | disc_loss: 0.7444231510162354 | gen_loss: 0.5496659278869629\n",
            "compute_gradients\n",
            "Epoch: 121 | disc_loss: 0.6982782483100891 | gen_loss: 0.5502612590789795\n",
            "compute_gradients\n",
            "Epoch: 122 | disc_loss: 0.7104613780975342 | gen_loss: 0.5507441163063049\n",
            "compute_gradients\n",
            "Epoch: 123 | disc_loss: 0.7325409054756165 | gen_loss: 0.5508906841278076\n",
            "compute_gradients\n",
            "Epoch: 124 | disc_loss: 0.8899821639060974 | gen_loss: 0.5512242913246155\n",
            "compute_gradients\n",
            "Epoch: 125 | disc_loss: 0.7000967264175415 | gen_loss: 0.5510804057121277\n",
            "compute_gradients\n",
            "Epoch: 126 | disc_loss: 0.6057528257369995 | gen_loss: 0.5526986122131348\n",
            "compute_gradients\n",
            "Epoch: 127 | disc_loss: 0.4240650236606598 | gen_loss: 0.5532782077789307\n",
            "compute_gradients\n",
            "Epoch: 128 | disc_loss: 0.63912034034729 | gen_loss: 0.5529051423072815\n",
            "compute_gradients\n",
            "Epoch: 129 | disc_loss: 0.6044850945472717 | gen_loss: 0.5509285926818848\n",
            "compute_gradients\n",
            "Epoch: 130 | disc_loss: 0.8500634431838989 | gen_loss: 0.5530962944030762\n",
            "compute_gradients\n",
            "Epoch: 131 | disc_loss: 0.590592086315155 | gen_loss: 0.5526368618011475\n",
            "compute_gradients\n",
            "Epoch: 132 | disc_loss: 0.5031514167785645 | gen_loss: 0.5525498390197754\n",
            "compute_gradients\n",
            "Epoch: 133 | disc_loss: 0.5688953399658203 | gen_loss: 0.5527393221855164\n",
            "compute_gradients\n",
            "Epoch: 134 | disc_loss: 0.29761821031570435 | gen_loss: 0.5530989766120911\n",
            "compute_gradients\n",
            "Epoch: 135 | disc_loss: 0.32693198323249817 | gen_loss: 0.5533643960952759\n",
            "compute_gradients\n",
            "Epoch: 136 | disc_loss: 0.22306638956069946 | gen_loss: 0.5532002449035645\n",
            "compute_gradients\n",
            "Epoch: 137 | disc_loss: 0.21610352396965027 | gen_loss: 0.5533525943756104\n",
            "compute_gradients\n",
            "Epoch: 138 | disc_loss: 0.33581656217575073 | gen_loss: 0.5545700192451477\n",
            "compute_gradients\n",
            "Epoch: 139 | disc_loss: 0.2448176145553589 | gen_loss: 0.553583562374115\n",
            "compute_gradients\n",
            "Epoch: 140 | disc_loss: 0.3260820209980011 | gen_loss: 0.5535016059875488\n",
            "compute_gradients\n",
            "Epoch: 141 | disc_loss: 0.30455195903778076 | gen_loss: 0.5540299415588379\n",
            "compute_gradients\n",
            "Epoch: 142 | disc_loss: 0.29869523644447327 | gen_loss: 0.555389940738678\n",
            "compute_gradients\n",
            "Epoch: 143 | disc_loss: 0.23465007543563843 | gen_loss: 0.5538012385368347\n",
            "compute_gradients\n",
            "Epoch: 144 | disc_loss: 0.20592010021209717 | gen_loss: 0.5547444820404053\n",
            "compute_gradients\n",
            "Epoch: 145 | disc_loss: 0.1872028410434723 | gen_loss: 0.555363655090332\n",
            "compute_gradients\n",
            "Epoch: 146 | disc_loss: 0.2502066493034363 | gen_loss: 0.5545281171798706\n",
            "compute_gradients\n",
            "Epoch: 147 | disc_loss: 0.11521223187446594 | gen_loss: 0.5553830862045288\n",
            "compute_gradients\n",
            "Epoch: 148 | disc_loss: 0.12003907561302185 | gen_loss: 0.5545770525932312\n",
            "compute_gradients\n",
            "Epoch: 149 | disc_loss: 0.10003170371055603 | gen_loss: 0.5555692911148071\n",
            "compute_gradients\n",
            "Epoch: 150 | disc_loss: 0.06772506237030029 | gen_loss: 0.5551398992538452\n",
            "compute_gradients\n",
            "Epoch: 151 | disc_loss: 0.09892876446247101 | gen_loss: 0.5565235018730164\n",
            "compute_gradients\n",
            "Epoch: 152 | disc_loss: 0.024677246809005737 | gen_loss: 0.5554262399673462\n",
            "compute_gradients\n",
            "Epoch: 153 | disc_loss: 0.07226802408695221 | gen_loss: 0.5570839047431946\n",
            "compute_gradients\n",
            "Epoch: 154 | disc_loss: 0.0970533937215805 | gen_loss: 0.5551199913024902\n",
            "compute_gradients\n",
            "Epoch: 155 | disc_loss: 0.08647900819778442 | gen_loss: 0.5577166080474854\n",
            "compute_gradients\n",
            "Epoch: 156 | disc_loss: 0.06594465672969818 | gen_loss: 0.5571110248565674\n",
            "compute_gradients\n",
            "Epoch: 157 | disc_loss: 0.01525619626045227 | gen_loss: 0.557614803314209\n",
            "compute_gradients\n",
            "Epoch: 158 | disc_loss: 0.03278017044067383 | gen_loss: 0.5574699640274048\n",
            "compute_gradients\n",
            "Epoch: 159 | disc_loss: -0.0010435059666633606 | gen_loss: 0.5584132671356201\n",
            "compute_gradients\n",
            "Epoch: 160 | disc_loss: -0.030179567635059357 | gen_loss: 0.556913435459137\n",
            "compute_gradients\n",
            "Epoch: 161 | disc_loss: -0.06793232262134552 | gen_loss: 0.5575041174888611\n",
            "compute_gradients\n",
            "Epoch: 162 | disc_loss: -0.05329297482967377 | gen_loss: 0.5579068660736084\n",
            "compute_gradients\n",
            "Epoch: 163 | disc_loss: -0.016379594802856445 | gen_loss: 0.5573620796203613\n",
            "compute_gradients\n",
            "Epoch: 164 | disc_loss: 0.026551544666290283 | gen_loss: 0.5571560859680176\n",
            "compute_gradients\n",
            "Epoch: 165 | disc_loss: -0.06122850626707077 | gen_loss: 0.5579456686973572\n",
            "compute_gradients\n",
            "Epoch: 166 | disc_loss: -0.05701028183102608 | gen_loss: 0.5565853714942932\n",
            "compute_gradients\n",
            "Epoch: 167 | disc_loss: -0.04241448640823364 | gen_loss: 0.5583207607269287\n",
            "compute_gradients\n",
            "Epoch: 168 | disc_loss: -0.06066935509443283 | gen_loss: 0.5576593279838562\n",
            "compute_gradients\n",
            "Epoch: 169 | disc_loss: -0.05927572399377823 | gen_loss: 0.5573245882987976\n",
            "compute_gradients\n",
            "Epoch: 170 | disc_loss: -0.06646159291267395 | gen_loss: 0.5569602251052856\n",
            "compute_gradients\n",
            "Epoch: 171 | disc_loss: -0.07405930012464523 | gen_loss: 0.558668315410614\n",
            "compute_gradients\n",
            "Epoch: 172 | disc_loss: -0.08380094170570374 | gen_loss: 0.5573402643203735\n",
            "compute_gradients\n",
            "Epoch: 173 | disc_loss: -0.08662167936563492 | gen_loss: 0.5568400025367737\n",
            "compute_gradients\n",
            "Epoch: 174 | disc_loss: -0.08956839889287949 | gen_loss: 0.5565717220306396\n",
            "compute_gradients\n",
            "Epoch: 175 | disc_loss: -0.08758548647165298 | gen_loss: 0.5579889416694641\n",
            "compute_gradients\n",
            "Epoch: 176 | disc_loss: -0.08513571321964264 | gen_loss: 0.5578732490539551\n",
            "compute_gradients\n",
            "Epoch: 177 | disc_loss: -0.07588734477758408 | gen_loss: 0.5585283041000366\n",
            "compute_gradients\n",
            "Epoch: 178 | disc_loss: -0.08242758363485336 | gen_loss: 0.5585341453552246\n",
            "compute_gradients\n",
            "Epoch: 179 | disc_loss: -0.086467444896698 | gen_loss: 0.5591942071914673\n",
            "compute_gradients\n",
            "Epoch: 180 | disc_loss: -0.08364629745483398 | gen_loss: 0.5587759017944336\n",
            "compute_gradients\n",
            "Epoch: 181 | disc_loss: -0.08416561782360077 | gen_loss: 0.5583617687225342\n",
            "compute_gradients\n",
            "Epoch: 182 | disc_loss: -0.0850864052772522 | gen_loss: 0.5582607388496399\n",
            "compute_gradients\n",
            "Epoch: 183 | disc_loss: -0.0827292948961258 | gen_loss: 0.560318112373352\n",
            "compute_gradients\n",
            "Epoch: 184 | disc_loss: -0.08631095290184021 | gen_loss: 0.5576724410057068\n",
            "compute_gradients\n",
            "Epoch: 185 | disc_loss: -0.09587569534778595 | gen_loss: 0.5595219731330872\n",
            "compute_gradients\n",
            "Epoch: 186 | disc_loss: -0.09327884018421173 | gen_loss: 0.5588732361793518\n",
            "compute_gradients\n",
            "Epoch: 187 | disc_loss: -0.08797502517700195 | gen_loss: 0.5594120025634766\n",
            "compute_gradients\n",
            "Epoch: 188 | disc_loss: -0.09345611184835434 | gen_loss: 0.5600241422653198\n",
            "compute_gradients\n",
            "Epoch: 189 | disc_loss: -0.06945783644914627 | gen_loss: 0.5594721436500549\n",
            "compute_gradients\n",
            "Epoch: 190 | disc_loss: -0.08064965903759003 | gen_loss: 0.5602333545684814\n",
            "compute_gradients\n",
            "Epoch: 191 | disc_loss: -0.08237439393997192 | gen_loss: 0.5621135830879211\n",
            "compute_gradients\n",
            "Epoch: 192 | disc_loss: -0.08749522268772125 | gen_loss: 0.560920774936676\n",
            "compute_gradients\n",
            "Epoch: 193 | disc_loss: -0.09119177609682083 | gen_loss: 0.5598544478416443\n",
            "compute_gradients\n",
            "Epoch: 194 | disc_loss: -0.08984899520874023 | gen_loss: 0.5597602725028992\n",
            "compute_gradients\n",
            "Epoch: 195 | disc_loss: -0.08197805285453796 | gen_loss: 0.5598576664924622\n",
            "compute_gradients\n",
            "Epoch: 196 | disc_loss: -0.09743944555521011 | gen_loss: 0.5603020787239075\n",
            "compute_gradients\n",
            "Epoch: 197 | disc_loss: -0.0913899838924408 | gen_loss: 0.5581236481666565\n",
            "compute_gradients\n",
            "Epoch: 198 | disc_loss: -0.08481525629758835 | gen_loss: 0.5596500635147095\n",
            "compute_gradients\n",
            "Epoch: 199 | disc_loss: -0.0881897509098053 | gen_loss: 0.5590097308158875\n",
            "compute_gradients\n",
            "Epoch: 200 | disc_loss: -0.08489736914634705 | gen_loss: 0.5604187250137329\n",
            "compute_gradients\n",
            "Epoch: 201 | disc_loss: -0.08183308690786362 | gen_loss: 0.5598558783531189\n",
            "compute_gradients\n",
            "Epoch: 202 | disc_loss: -0.0880732610821724 | gen_loss: 0.5603241920471191\n",
            "compute_gradients\n",
            "Epoch: 203 | disc_loss: -0.09311412274837494 | gen_loss: 0.5615561008453369\n",
            "compute_gradients\n",
            "Epoch: 204 | disc_loss: -0.08773032575845718 | gen_loss: 0.5615866184234619\n",
            "compute_gradients\n",
            "Epoch: 205 | disc_loss: -0.08070538192987442 | gen_loss: 0.560046911239624\n",
            "compute_gradients\n",
            "Epoch: 206 | disc_loss: -0.09301278740167618 | gen_loss: 0.5606322884559631\n",
            "compute_gradients\n",
            "Epoch: 207 | disc_loss: -0.08767984062433243 | gen_loss: 0.5581704378128052\n",
            "compute_gradients\n",
            "Epoch: 208 | disc_loss: -0.08628720045089722 | gen_loss: 0.5608305335044861\n",
            "compute_gradients\n",
            "Epoch: 209 | disc_loss: -0.07676881551742554 | gen_loss: 0.5611624121665955\n",
            "compute_gradients\n",
            "Epoch: 210 | disc_loss: -0.08962535858154297 | gen_loss: 0.5607993602752686\n",
            "compute_gradients\n",
            "Epoch: 211 | disc_loss: -0.09191964566707611 | gen_loss: 0.5596597790718079\n",
            "compute_gradients\n",
            "Epoch: 212 | disc_loss: -0.08459917455911636 | gen_loss: 0.5597341656684875\n",
            "compute_gradients\n",
            "Epoch: 213 | disc_loss: -0.08223430067300797 | gen_loss: 0.5605623722076416\n",
            "compute_gradients\n",
            "Epoch: 214 | disc_loss: -0.08741903305053711 | gen_loss: 0.5627750754356384\n",
            "compute_gradients\n",
            "Epoch: 215 | disc_loss: -0.08614429831504822 | gen_loss: 0.5618510246276855\n",
            "compute_gradients\n",
            "Epoch: 216 | disc_loss: -0.07921001315116882 | gen_loss: 0.5635100603103638\n",
            "compute_gradients\n",
            "Epoch: 217 | disc_loss: -0.09219779074192047 | gen_loss: 0.56313157081604\n",
            "compute_gradients\n",
            "Epoch: 218 | disc_loss: -0.08063190430402756 | gen_loss: 0.5600265264511108\n",
            "compute_gradients\n",
            "Epoch: 219 | disc_loss: -0.08085519820451736 | gen_loss: 0.5624545216560364\n",
            "compute_gradients\n",
            "Epoch: 220 | disc_loss: -0.08329587429761887 | gen_loss: 0.561923623085022\n",
            "compute_gradients\n",
            "Epoch: 221 | disc_loss: -0.08002372831106186 | gen_loss: 0.5622419118881226\n",
            "compute_gradients\n",
            "Epoch: 222 | disc_loss: -0.08440668135881424 | gen_loss: 0.5645925998687744\n",
            "compute_gradients\n",
            "Epoch: 223 | disc_loss: -0.08989492058753967 | gen_loss: 0.5628429651260376\n",
            "compute_gradients\n",
            "Epoch: 224 | disc_loss: -0.07151453197002411 | gen_loss: 0.5628061294555664\n",
            "compute_gradients\n",
            "Epoch: 225 | disc_loss: -0.0724957287311554 | gen_loss: 0.5632174015045166\n",
            "compute_gradients\n",
            "Epoch: 226 | disc_loss: -0.08865457028150558 | gen_loss: 0.5620582699775696\n",
            "compute_gradients\n",
            "Epoch: 227 | disc_loss: -0.06992711126804352 | gen_loss: 0.5652763247489929\n",
            "compute_gradients\n",
            "Epoch: 228 | disc_loss: -0.07415883243083954 | gen_loss: 0.5634423494338989\n",
            "compute_gradients\n",
            "Epoch: 229 | disc_loss: -0.08837463706731796 | gen_loss: 0.5653541088104248\n",
            "compute_gradients\n",
            "Epoch: 230 | disc_loss: -0.08339184522628784 | gen_loss: 0.5641524791717529\n",
            "compute_gradients\n",
            "Epoch: 231 | disc_loss: -0.08950591087341309 | gen_loss: 0.5645477771759033\n",
            "compute_gradients\n",
            "Epoch: 232 | disc_loss: -0.09395755082368851 | gen_loss: 0.5653120279312134\n",
            "compute_gradients\n",
            "Epoch: 233 | disc_loss: -0.08875378966331482 | gen_loss: 0.563483715057373\n",
            "compute_gradients\n",
            "Epoch: 234 | disc_loss: -0.09451808780431747 | gen_loss: 0.563880980014801\n",
            "compute_gradients\n",
            "Epoch: 235 | disc_loss: -0.09256914258003235 | gen_loss: 0.5640770196914673\n",
            "compute_gradients\n",
            "Epoch: 236 | disc_loss: -0.07886167615652084 | gen_loss: 0.5628737211227417\n",
            "compute_gradients\n",
            "Epoch: 237 | disc_loss: -0.06483762711286545 | gen_loss: 0.563600480556488\n",
            "compute_gradients\n",
            "Epoch: 238 | disc_loss: -0.10328890383243561 | gen_loss: 0.5638500452041626\n",
            "compute_gradients\n",
            "Epoch: 239 | disc_loss: -0.0657268688082695 | gen_loss: 0.5640477538108826\n",
            "compute_gradients\n",
            "Epoch: 240 | disc_loss: -0.06356337666511536 | gen_loss: 0.5665480494499207\n",
            "compute_gradients\n",
            "Epoch: 241 | disc_loss: -0.07892907410860062 | gen_loss: 0.5669885873794556\n",
            "compute_gradients\n",
            "Epoch: 242 | disc_loss: -0.08597013354301453 | gen_loss: 0.5664408206939697\n",
            "compute_gradients\n",
            "Epoch: 243 | disc_loss: -0.07611919939517975 | gen_loss: 0.5645409226417542\n",
            "compute_gradients\n",
            "Epoch: 244 | disc_loss: -0.07622022181749344 | gen_loss: 0.5669080018997192\n",
            "compute_gradients\n",
            "Epoch: 245 | disc_loss: -0.0798778235912323 | gen_loss: 0.564595103263855\n",
            "compute_gradients\n",
            "Epoch: 246 | disc_loss: -0.08208561688661575 | gen_loss: 0.5646932125091553\n",
            "compute_gradients\n",
            "Epoch: 247 | disc_loss: -0.08206365257501602 | gen_loss: 0.5657165050506592\n",
            "compute_gradients\n",
            "Epoch: 248 | disc_loss: -0.08512657880783081 | gen_loss: 0.5647597312927246\n",
            "compute_gradients\n",
            "Epoch: 249 | disc_loss: -0.08132784813642502 | gen_loss: 0.5645524859428406\n",
            "compute_gradients\n",
            "Epoch: 250 | disc_loss: -0.06657258421182632 | gen_loss: 0.5667842626571655\n",
            "compute_gradients\n",
            "Epoch: 251 | disc_loss: -0.08793515712022781 | gen_loss: 0.5664931535720825\n",
            "compute_gradients\n",
            "Epoch: 252 | disc_loss: -0.08630689233541489 | gen_loss: 0.5672751069068909\n",
            "compute_gradients\n",
            "Epoch: 253 | disc_loss: -0.08639054000377655 | gen_loss: 0.5652714371681213\n",
            "compute_gradients\n",
            "Epoch: 254 | disc_loss: -0.06464007496833801 | gen_loss: 0.5670271515846252\n",
            "compute_gradients\n",
            "Epoch: 255 | disc_loss: -0.06505435705184937 | gen_loss: 0.5666444301605225\n",
            "compute_gradients\n",
            "Epoch: 256 | disc_loss: -0.08216382563114166 | gen_loss: 0.5668783783912659\n",
            "compute_gradients\n",
            "Epoch: 257 | disc_loss: -0.07435397058725357 | gen_loss: 0.5663040280342102\n",
            "compute_gradients\n",
            "Epoch: 258 | disc_loss: -0.08946914225816727 | gen_loss: 0.5686696171760559\n",
            "compute_gradients\n",
            "Epoch: 259 | disc_loss: -0.08200062066316605 | gen_loss: 0.5662411451339722\n",
            "compute_gradients\n",
            "Epoch: 260 | disc_loss: -0.08046203851699829 | gen_loss: 0.5684361457824707\n",
            "compute_gradients\n",
            "Epoch: 261 | disc_loss: -0.074526846408844 | gen_loss: 0.5665249824523926\n",
            "compute_gradients\n",
            "Epoch: 262 | disc_loss: -0.0874403640627861 | gen_loss: 0.5672862529754639\n",
            "compute_gradients\n",
            "Epoch: 263 | disc_loss: -0.07328933477401733 | gen_loss: 0.5679051280021667\n",
            "compute_gradients\n",
            "Epoch: 264 | disc_loss: -0.08942347764968872 | gen_loss: 0.5696027278900146\n",
            "compute_gradients\n",
            "Epoch: 265 | disc_loss: -0.09001407027244568 | gen_loss: 0.5669803023338318\n",
            "compute_gradients\n",
            "Epoch: 266 | disc_loss: -0.0680847316980362 | gen_loss: 0.5680819153785706\n",
            "compute_gradients\n",
            "Epoch: 267 | disc_loss: -0.08128514140844345 | gen_loss: 0.5676330327987671\n",
            "compute_gradients\n",
            "Epoch: 268 | disc_loss: -0.0729580670595169 | gen_loss: 0.5668997764587402\n",
            "compute_gradients\n",
            "Epoch: 269 | disc_loss: -0.06694232672452927 | gen_loss: 0.5688887238502502\n",
            "compute_gradients\n",
            "Epoch: 270 | disc_loss: -0.08411531150341034 | gen_loss: 0.5683459639549255\n",
            "compute_gradients\n",
            "Epoch: 271 | disc_loss: -0.07838283479213715 | gen_loss: 0.568783700466156\n",
            "compute_gradients\n",
            "Epoch: 272 | disc_loss: -0.08188895881175995 | gen_loss: 0.5697618126869202\n",
            "compute_gradients\n",
            "Epoch: 273 | disc_loss: -0.08008385449647903 | gen_loss: 0.5697627067565918\n",
            "compute_gradients\n",
            "Epoch: 274 | disc_loss: -0.0839921310544014 | gen_loss: 0.5674617886543274\n",
            "compute_gradients\n",
            "Epoch: 275 | disc_loss: -0.07120843231678009 | gen_loss: 0.56975919008255\n",
            "compute_gradients\n",
            "Epoch: 276 | disc_loss: -0.09149769693613052 | gen_loss: 0.5699113607406616\n",
            "compute_gradients\n",
            "Epoch: 277 | disc_loss: -0.06427927315235138 | gen_loss: 0.5696528553962708\n",
            "compute_gradients\n",
            "Epoch: 278 | disc_loss: -0.0868397206068039 | gen_loss: 0.5695686340332031\n",
            "compute_gradients\n",
            "Epoch: 279 | disc_loss: -0.07846793532371521 | gen_loss: 0.5706793069839478\n",
            "compute_gradients\n",
            "Epoch: 280 | disc_loss: -0.09016498923301697 | gen_loss: 0.5722960829734802\n",
            "compute_gradients\n",
            "Epoch: 281 | disc_loss: -0.0853961929678917 | gen_loss: 0.5690981149673462\n",
            "compute_gradients\n",
            "Epoch: 282 | disc_loss: -0.06861700862646103 | gen_loss: 0.5703248381614685\n",
            "compute_gradients\n",
            "Epoch: 283 | disc_loss: -0.07578794658184052 | gen_loss: 0.5715804696083069\n",
            "compute_gradients\n",
            "Epoch: 284 | disc_loss: -0.06509783118963242 | gen_loss: 0.5699210166931152\n",
            "compute_gradients\n",
            "Epoch: 285 | disc_loss: -0.07833027839660645 | gen_loss: 0.5717215538024902\n",
            "compute_gradients\n",
            "Epoch: 286 | disc_loss: -0.06506141275167465 | gen_loss: 0.5692179203033447\n",
            "compute_gradients\n",
            "Epoch: 287 | disc_loss: -0.06860571354627609 | gen_loss: 0.5701276659965515\n",
            "compute_gradients\n",
            "Epoch: 288 | disc_loss: -0.08031948655843735 | gen_loss: 0.5705531239509583\n",
            "compute_gradients\n",
            "Epoch: 289 | disc_loss: -0.08121068775653839 | gen_loss: 0.5726309418678284\n",
            "compute_gradients\n",
            "Epoch: 290 | disc_loss: -0.08588550239801407 | gen_loss: 0.570330798625946\n",
            "compute_gradients\n",
            "Epoch: 291 | disc_loss: -0.08560456335544586 | gen_loss: 0.5728715658187866\n",
            "compute_gradients\n",
            "Epoch: 292 | disc_loss: -0.06390367448329926 | gen_loss: 0.5699191093444824\n",
            "compute_gradients\n",
            "Epoch: 293 | disc_loss: -0.07850158214569092 | gen_loss: 0.5708580613136292\n",
            "compute_gradients\n",
            "Epoch: 294 | disc_loss: -0.09247475862503052 | gen_loss: 0.5701140761375427\n",
            "compute_gradients\n",
            "Epoch: 295 | disc_loss: -0.06023545563220978 | gen_loss: 0.57231205701828\n",
            "compute_gradients\n",
            "Epoch: 296 | disc_loss: -0.07551409304141998 | gen_loss: 0.5703790783882141\n",
            "compute_gradients\n",
            "Epoch: 297 | disc_loss: -0.07456009835004807 | gen_loss: 0.5725979804992676\n",
            "compute_gradients\n",
            "Epoch: 298 | disc_loss: -0.08468103408813477 | gen_loss: 0.5722423791885376\n",
            "compute_gradients\n",
            "Epoch: 299 | disc_loss: -0.09128278493881226 | gen_loss: 0.5718849301338196\n",
            "compute_gradients\n",
            "Epoch: 300 | disc_loss: -0.0643501803278923 | gen_loss: 0.5704966187477112\n",
            "compute_gradients\n",
            "Epoch: 301 | disc_loss: -0.05908556655049324 | gen_loss: 0.5709508061408997\n",
            "compute_gradients\n",
            "Epoch: 302 | disc_loss: -0.0816245749592781 | gen_loss: 0.5716516375541687\n",
            "compute_gradients\n",
            "Epoch: 303 | disc_loss: -0.08044657111167908 | gen_loss: 0.5730103254318237\n",
            "compute_gradients\n",
            "Epoch: 304 | disc_loss: -0.04608561098575592 | gen_loss: 0.5725988149642944\n",
            "compute_gradients\n",
            "Epoch: 305 | disc_loss: -0.07814306020736694 | gen_loss: 0.571992039680481\n",
            "compute_gradients\n",
            "Epoch: 306 | disc_loss: -0.07752539962530136 | gen_loss: 0.5736860036849976\n",
            "compute_gradients\n",
            "Epoch: 307 | disc_loss: -0.07889315485954285 | gen_loss: 0.5758654475212097\n",
            "compute_gradients\n",
            "Epoch: 308 | disc_loss: -0.0870678573846817 | gen_loss: 0.5733724236488342\n",
            "compute_gradients\n",
            "Epoch: 309 | disc_loss: -0.06456010043621063 | gen_loss: 0.5725465416908264\n",
            "compute_gradients\n",
            "Epoch: 310 | disc_loss: -0.07206065952777863 | gen_loss: 0.5739410519599915\n",
            "compute_gradients\n",
            "Epoch: 311 | disc_loss: -0.08441776037216187 | gen_loss: 0.5750256180763245\n",
            "compute_gradients\n",
            "Epoch: 312 | disc_loss: -0.059923917055130005 | gen_loss: 0.576566219329834\n",
            "compute_gradients\n",
            "Epoch: 313 | disc_loss: -0.06963986158370972 | gen_loss: 0.5724939107894897\n",
            "compute_gradients\n",
            "Epoch: 314 | disc_loss: 0.0015151724219322205 | gen_loss: 0.5750935673713684\n",
            "compute_gradients\n",
            "Epoch: 315 | disc_loss: -0.07039132714271545 | gen_loss: 0.5752792954444885\n",
            "compute_gradients\n",
            "Epoch: 316 | disc_loss: -0.07280483096837997 | gen_loss: 0.5728052854537964\n",
            "compute_gradients\n",
            "Epoch: 317 | disc_loss: -0.0820077583193779 | gen_loss: 0.5745421648025513\n",
            "compute_gradients\n",
            "Epoch: 318 | disc_loss: -0.07695857435464859 | gen_loss: 0.573809802532196\n",
            "compute_gradients\n",
            "Epoch: 319 | disc_loss: -0.07431015372276306 | gen_loss: 0.5755020976066589\n",
            "compute_gradients\n",
            "Epoch: 320 | disc_loss: -0.08616245537996292 | gen_loss: 0.576426088809967\n",
            "compute_gradients\n",
            "Epoch: 321 | disc_loss: -0.07527290284633636 | gen_loss: 0.5745002627372742\n",
            "compute_gradients\n",
            "Epoch: 322 | disc_loss: -0.05676102638244629 | gen_loss: 0.575396716594696\n",
            "compute_gradients\n",
            "Epoch: 323 | disc_loss: -0.08696965873241425 | gen_loss: 0.5763152837753296\n",
            "compute_gradients\n",
            "Epoch: 324 | disc_loss: -0.07149744778871536 | gen_loss: 0.5729587078094482\n",
            "compute_gradients\n",
            "Epoch: 325 | disc_loss: -0.075110524892807 | gen_loss: 0.5777987837791443\n",
            "compute_gradients\n",
            "Epoch: 326 | disc_loss: -0.06773802638053894 | gen_loss: 0.575959324836731\n",
            "compute_gradients\n",
            "Epoch: 327 | disc_loss: -0.06437170505523682 | gen_loss: 0.5763697624206543\n",
            "compute_gradients\n",
            "Epoch: 328 | disc_loss: -0.08528325706720352 | gen_loss: 0.5777872800827026\n",
            "compute_gradients\n",
            "Epoch: 329 | disc_loss: -0.05711192265152931 | gen_loss: 0.5752652883529663\n",
            "compute_gradients\n",
            "Epoch: 330 | disc_loss: -0.07342707365751266 | gen_loss: 0.575164794921875\n",
            "compute_gradients\n",
            "Epoch: 331 | disc_loss: -0.08631296455860138 | gen_loss: 0.5781559348106384\n",
            "compute_gradients\n",
            "Epoch: 332 | disc_loss: -0.05530690401792526 | gen_loss: 0.5789492726325989\n",
            "compute_gradients\n",
            "Epoch: 333 | disc_loss: -0.06477927416563034 | gen_loss: 0.5764185190200806\n",
            "compute_gradients\n",
            "Epoch: 334 | disc_loss: -0.07905692607164383 | gen_loss: 0.5790690779685974\n",
            "compute_gradients\n",
            "Epoch: 335 | disc_loss: -0.0850788950920105 | gen_loss: 0.57682204246521\n",
            "compute_gradients\n",
            "Epoch: 336 | disc_loss: -0.07973992079496384 | gen_loss: 0.5795093774795532\n",
            "compute_gradients\n",
            "Epoch: 337 | disc_loss: -0.029847610741853714 | gen_loss: 0.5786850452423096\n",
            "compute_gradients\n",
            "Epoch: 338 | disc_loss: -0.08190436661243439 | gen_loss: 0.5791871547698975\n",
            "compute_gradients\n",
            "Epoch: 339 | disc_loss: -0.07326363027095795 | gen_loss: 0.5782988667488098\n",
            "compute_gradients\n",
            "Epoch: 340 | disc_loss: -0.08699880540370941 | gen_loss: 0.5787859559059143\n",
            "compute_gradients\n",
            "Epoch: 341 | disc_loss: -0.06934216618537903 | gen_loss: 0.5782869458198547\n",
            "compute_gradients\n",
            "Epoch: 342 | disc_loss: -0.052783507853746414 | gen_loss: 0.5777549147605896\n",
            "compute_gradients\n",
            "Epoch: 343 | disc_loss: -0.07720301300287247 | gen_loss: 0.5789989829063416\n",
            "compute_gradients\n",
            "Epoch: 344 | disc_loss: -0.040397100150585175 | gen_loss: 0.577142596244812\n",
            "compute_gradients\n",
            "Epoch: 345 | disc_loss: -0.07906942814588547 | gen_loss: 0.578683614730835\n",
            "compute_gradients\n",
            "Epoch: 346 | disc_loss: -0.08086986839771271 | gen_loss: 0.580873966217041\n",
            "compute_gradients\n",
            "Epoch: 347 | disc_loss: -0.06978141516447067 | gen_loss: 0.5786181092262268\n",
            "compute_gradients\n",
            "Epoch: 348 | disc_loss: -0.08101484179496765 | gen_loss: 0.5793004631996155\n",
            "compute_gradients\n",
            "Epoch: 349 | disc_loss: -0.06391660869121552 | gen_loss: 0.5782073736190796\n",
            "compute_gradients\n",
            "Epoch: 350 | disc_loss: -0.08399714529514313 | gen_loss: 0.580167293548584\n",
            "compute_gradients\n",
            "Epoch: 351 | disc_loss: -0.06858867406845093 | gen_loss: 0.5807594060897827\n",
            "compute_gradients\n",
            "Epoch: 352 | disc_loss: -0.07775678485631943 | gen_loss: 0.5794626474380493\n",
            "compute_gradients\n",
            "Epoch: 353 | disc_loss: -0.07916736602783203 | gen_loss: 0.5796682834625244\n",
            "compute_gradients\n",
            "Epoch: 354 | disc_loss: -0.06313780695199966 | gen_loss: 0.5789358615875244\n",
            "compute_gradients\n",
            "Epoch: 355 | disc_loss: -0.060057416558265686 | gen_loss: 0.5777850151062012\n",
            "compute_gradients\n",
            "Epoch: 356 | disc_loss: -0.0678609311580658 | gen_loss: 0.5814802646636963\n",
            "compute_gradients\n",
            "Epoch: 357 | disc_loss: -0.07663202285766602 | gen_loss: 0.5820288062095642\n",
            "compute_gradients\n",
            "Epoch: 358 | disc_loss: -0.03580380231142044 | gen_loss: 0.5806231498718262\n",
            "compute_gradients\n",
            "Epoch: 359 | disc_loss: -0.08078472316265106 | gen_loss: 0.5814935564994812\n",
            "compute_gradients\n",
            "Epoch: 360 | disc_loss: -0.07459103316068649 | gen_loss: 0.5813265442848206\n",
            "compute_gradients\n",
            "Epoch: 361 | disc_loss: -0.06925302743911743 | gen_loss: 0.5797511339187622\n",
            "compute_gradients\n",
            "Epoch: 362 | disc_loss: -0.06841731071472168 | gen_loss: 0.5831798315048218\n",
            "compute_gradients\n",
            "Epoch: 363 | disc_loss: -0.07139664888381958 | gen_loss: 0.5845074653625488\n",
            "compute_gradients\n",
            "Epoch: 364 | disc_loss: -0.07903027534484863 | gen_loss: 0.5820955634117126\n",
            "compute_gradients\n",
            "Epoch: 365 | disc_loss: -0.06784339249134064 | gen_loss: 0.578657329082489\n",
            "compute_gradients\n",
            "Epoch: 366 | disc_loss: -0.06599149852991104 | gen_loss: 0.580457329750061\n",
            "compute_gradients\n",
            "Epoch: 367 | disc_loss: -0.07819238305091858 | gen_loss: 0.584205687046051\n",
            "compute_gradients\n",
            "Epoch: 368 | disc_loss: -0.08936849236488342 | gen_loss: 0.5825462341308594\n",
            "compute_gradients\n",
            "Epoch: 369 | disc_loss: -0.0756300836801529 | gen_loss: 0.5809499025344849\n",
            "compute_gradients\n",
            "Epoch: 370 | disc_loss: -0.03891061246395111 | gen_loss: 0.5794849991798401\n",
            "compute_gradients\n",
            "Epoch: 371 | disc_loss: -0.06640508770942688 | gen_loss: 0.5806081295013428\n",
            "compute_gradients\n",
            "Epoch: 372 | disc_loss: -0.07044914364814758 | gen_loss: 0.5824544429779053\n",
            "compute_gradients\n",
            "Epoch: 373 | disc_loss: -0.023740947246551514 | gen_loss: 0.5805109143257141\n",
            "compute_gradients\n",
            "Epoch: 374 | disc_loss: -0.07493814826011658 | gen_loss: 0.5816657543182373\n",
            "compute_gradients\n",
            "Epoch: 375 | disc_loss: -0.07789190858602524 | gen_loss: 0.582323431968689\n",
            "compute_gradients\n",
            "Epoch: 376 | disc_loss: -0.07244189083576202 | gen_loss: 0.5808143615722656\n",
            "compute_gradients\n",
            "Epoch: 377 | disc_loss: -0.07118462771177292 | gen_loss: 0.583173930644989\n",
            "compute_gradients\n",
            "Epoch: 378 | disc_loss: -0.08116143941879272 | gen_loss: 0.5814052820205688\n",
            "compute_gradients\n",
            "Epoch: 379 | disc_loss: -0.07389435172080994 | gen_loss: 0.5813013911247253\n",
            "compute_gradients\n",
            "Epoch: 380 | disc_loss: -0.07363627105951309 | gen_loss: 0.5835363864898682\n",
            "compute_gradients\n",
            "Epoch: 381 | disc_loss: -0.06752298772335052 | gen_loss: 0.581691324710846\n",
            "compute_gradients\n",
            "Epoch: 382 | disc_loss: -0.08080019801855087 | gen_loss: 0.5833637118339539\n",
            "compute_gradients\n",
            "Epoch: 383 | disc_loss: -0.06958790123462677 | gen_loss: 0.5825710892677307\n",
            "compute_gradients\n",
            "Epoch: 384 | disc_loss: -0.07556632906198502 | gen_loss: 0.5815485119819641\n",
            "compute_gradients\n",
            "Epoch: 385 | disc_loss: -0.051967691630125046 | gen_loss: 0.5831180810928345\n",
            "compute_gradients\n",
            "Epoch: 386 | disc_loss: -0.05038522183895111 | gen_loss: 0.5810954570770264\n",
            "compute_gradients\n",
            "Epoch: 387 | disc_loss: -0.07007312029600143 | gen_loss: 0.5838325619697571\n",
            "compute_gradients\n",
            "Epoch: 388 | disc_loss: -0.06512495875358582 | gen_loss: 0.5829266905784607\n",
            "compute_gradients\n",
            "Epoch: 389 | disc_loss: -0.04511271417140961 | gen_loss: 0.5840969681739807\n",
            "compute_gradients\n",
            "Epoch: 390 | disc_loss: -0.07102172076702118 | gen_loss: 0.5851910710334778\n",
            "compute_gradients\n",
            "Epoch: 391 | disc_loss: -0.06014948710799217 | gen_loss: 0.5832710266113281\n",
            "compute_gradients\n",
            "Epoch: 392 | disc_loss: -0.07744166254997253 | gen_loss: 0.5841192603111267\n",
            "compute_gradients\n",
            "Epoch: 393 | disc_loss: -0.07496669888496399 | gen_loss: 0.5854257345199585\n",
            "compute_gradients\n",
            "Epoch: 394 | disc_loss: -0.07497313618659973 | gen_loss: 0.5861462354660034\n",
            "compute_gradients\n",
            "Epoch: 395 | disc_loss: -0.06578230857849121 | gen_loss: 0.5837910175323486\n",
            "compute_gradients\n",
            "Epoch: 396 | disc_loss: -0.05444253981113434 | gen_loss: 0.585654079914093\n",
            "compute_gradients\n",
            "Epoch: 397 | disc_loss: -0.07444719970226288 | gen_loss: 0.5869960784912109\n",
            "compute_gradients\n",
            "Epoch: 398 | disc_loss: -0.07521159946918488 | gen_loss: 0.5868696570396423\n",
            "compute_gradients\n",
            "Epoch: 399 | disc_loss: -0.06901396065950394 | gen_loss: 0.5868624448776245\n",
            "compute_gradients\n",
            "Epoch: 400 | disc_loss: -0.06747528910636902 | gen_loss: 0.5843036770820618\n",
            "compute_gradients\n",
            "Epoch: 401 | disc_loss: -0.07914431393146515 | gen_loss: 0.584099531173706\n",
            "compute_gradients\n",
            "Epoch: 402 | disc_loss: -0.07747897505760193 | gen_loss: 0.5837268233299255\n",
            "compute_gradients\n",
            "Epoch: 403 | disc_loss: -0.06278309226036072 | gen_loss: 0.584984302520752\n",
            "compute_gradients\n",
            "Epoch: 404 | disc_loss: -0.05337264761328697 | gen_loss: 0.5832605361938477\n",
            "compute_gradients\n",
            "Epoch: 405 | disc_loss: -0.04487625136971474 | gen_loss: 0.5885393023490906\n",
            "compute_gradients\n",
            "Epoch: 406 | disc_loss: -0.055804669857025146 | gen_loss: 0.5844292640686035\n",
            "compute_gradients\n",
            "Epoch: 407 | disc_loss: -0.08143267035484314 | gen_loss: 0.5871970653533936\n",
            "compute_gradients\n",
            "Epoch: 408 | disc_loss: -0.07519904524087906 | gen_loss: 0.5858002305030823\n",
            "compute_gradients\n",
            "Epoch: 409 | disc_loss: -0.06667838245630264 | gen_loss: 0.5867106914520264\n",
            "compute_gradients\n",
            "Epoch: 410 | disc_loss: -0.05705810338258743 | gen_loss: 0.5826119184494019\n",
            "compute_gradients\n",
            "Epoch: 411 | disc_loss: -0.06598013639450073 | gen_loss: 0.5826456546783447\n",
            "compute_gradients\n",
            "Epoch: 412 | disc_loss: -0.060890525579452515 | gen_loss: 0.5833271741867065\n",
            "compute_gradients\n",
            "Epoch: 413 | disc_loss: -0.05181325972080231 | gen_loss: 0.584604799747467\n",
            "compute_gradients\n",
            "Epoch: 414 | disc_loss: -0.06483805179595947 | gen_loss: 0.5876004695892334\n",
            "compute_gradients\n",
            "Epoch: 415 | disc_loss: -0.0714157372713089 | gen_loss: 0.585924506187439\n",
            "compute_gradients\n",
            "Epoch: 416 | disc_loss: -0.062489740550518036 | gen_loss: 0.5849859714508057\n",
            "compute_gradients\n",
            "Epoch: 417 | disc_loss: -0.07769838720560074 | gen_loss: 0.5866235494613647\n",
            "compute_gradients\n",
            "Epoch: 418 | disc_loss: -0.06155352666974068 | gen_loss: 0.5865116715431213\n",
            "compute_gradients\n",
            "Epoch: 419 | disc_loss: -0.06768245249986649 | gen_loss: 0.5877225399017334\n",
            "compute_gradients\n",
            "Epoch: 420 | disc_loss: -0.06815837323665619 | gen_loss: 0.5863350629806519\n",
            "compute_gradients\n",
            "Epoch: 421 | disc_loss: -0.0731215626001358 | gen_loss: 0.5870206952095032\n",
            "compute_gradients\n",
            "Epoch: 422 | disc_loss: -0.06335725635290146 | gen_loss: 0.5881422162055969\n",
            "compute_gradients\n",
            "Epoch: 423 | disc_loss: -0.05546169728040695 | gen_loss: 0.5914623737335205\n",
            "compute_gradients\n",
            "Epoch: 424 | disc_loss: -0.06729482114315033 | gen_loss: 0.5860676169395447\n",
            "compute_gradients\n",
            "Epoch: 425 | disc_loss: -0.08148028701543808 | gen_loss: 0.5876457691192627\n",
            "compute_gradients\n",
            "Epoch: 426 | disc_loss: -0.06660370528697968 | gen_loss: 0.5880897045135498\n",
            "compute_gradients\n",
            "Epoch: 427 | disc_loss: -0.043057218194007874 | gen_loss: 0.5899976491928101\n",
            "compute_gradients\n",
            "Epoch: 428 | disc_loss: -0.057772159576416016 | gen_loss: 0.5869503021240234\n",
            "compute_gradients\n",
            "Epoch: 429 | disc_loss: -0.07242327183485031 | gen_loss: 0.5873771905899048\n",
            "compute_gradients\n",
            "Epoch: 430 | disc_loss: -0.057575397193431854 | gen_loss: 0.5866574048995972\n",
            "compute_gradients\n",
            "Epoch: 431 | disc_loss: -0.02917763590812683 | gen_loss: 0.5882437229156494\n",
            "compute_gradients\n",
            "Epoch: 432 | disc_loss: -0.0706595927476883 | gen_loss: 0.5892303586006165\n",
            "compute_gradients\n",
            "Epoch: 433 | disc_loss: -0.07224395126104355 | gen_loss: 0.591407060623169\n",
            "compute_gradients\n",
            "Epoch: 434 | disc_loss: -0.06709019094705582 | gen_loss: 0.588793158531189\n",
            "compute_gradients\n",
            "Epoch: 435 | disc_loss: -0.06893408298492432 | gen_loss: 0.5887600779533386\n",
            "compute_gradients\n",
            "Epoch: 436 | disc_loss: -0.06472291052341461 | gen_loss: 0.5897597670555115\n",
            "compute_gradients\n",
            "Epoch: 437 | disc_loss: -0.07713217288255692 | gen_loss: 0.5894509553909302\n",
            "compute_gradients\n",
            "Epoch: 438 | disc_loss: -0.07093658298254013 | gen_loss: 0.587106466293335\n",
            "compute_gradients\n",
            "Epoch: 439 | disc_loss: -0.07716534286737442 | gen_loss: 0.5892001986503601\n",
            "compute_gradients\n",
            "Epoch: 440 | disc_loss: -0.04091788828372955 | gen_loss: 0.5909322500228882\n",
            "compute_gradients\n",
            "Epoch: 441 | disc_loss: -0.07348281890153885 | gen_loss: 0.5878233313560486\n",
            "compute_gradients\n",
            "Epoch: 442 | disc_loss: -0.06914396584033966 | gen_loss: 0.5888570547103882\n",
            "compute_gradients\n",
            "Epoch: 443 | disc_loss: -0.06525368988513947 | gen_loss: 0.5885236859321594\n",
            "compute_gradients\n",
            "Epoch: 444 | disc_loss: -0.07325979322195053 | gen_loss: 0.5889453887939453\n",
            "compute_gradients\n",
            "Epoch: 445 | disc_loss: -0.07195090502500534 | gen_loss: 0.5878850221633911\n",
            "compute_gradients\n",
            "Epoch: 446 | disc_loss: -0.072085902094841 | gen_loss: 0.5902875661849976\n",
            "compute_gradients\n",
            "Epoch: 447 | disc_loss: -0.02752842754125595 | gen_loss: 0.5910446643829346\n",
            "compute_gradients\n",
            "Epoch: 448 | disc_loss: -0.07836085557937622 | gen_loss: 0.5888097882270813\n",
            "compute_gradients\n",
            "Epoch: 449 | disc_loss: -0.06314712762832642 | gen_loss: 0.5892022252082825\n",
            "compute_gradients\n",
            "Epoch: 450 | disc_loss: -0.06353913992643356 | gen_loss: 0.5886553525924683\n",
            "compute_gradients\n",
            "Epoch: 451 | disc_loss: -0.07837313413619995 | gen_loss: 0.5889897346496582\n",
            "compute_gradients\n",
            "Epoch: 452 | disc_loss: -0.06674332171678543 | gen_loss: 0.5895334482192993\n",
            "compute_gradients\n",
            "Epoch: 453 | disc_loss: -0.003034427762031555 | gen_loss: 0.5918203592300415\n",
            "compute_gradients\n",
            "Epoch: 454 | disc_loss: -0.05075439065694809 | gen_loss: 0.5877479314804077\n",
            "compute_gradients\n",
            "Epoch: 455 | disc_loss: -0.06955066323280334 | gen_loss: 0.5899903178215027\n",
            "compute_gradients\n",
            "Epoch: 456 | disc_loss: -0.0680902972817421 | gen_loss: 0.5898572206497192\n",
            "compute_gradients\n",
            "Epoch: 457 | disc_loss: -0.06010378152132034 | gen_loss: 0.5876322984695435\n",
            "compute_gradients\n",
            "Epoch: 458 | disc_loss: -0.07624603807926178 | gen_loss: 0.5881134271621704\n",
            "compute_gradients\n",
            "Epoch: 459 | disc_loss: -0.05926740914583206 | gen_loss: 0.5888795256614685\n",
            "compute_gradients\n",
            "Epoch: 460 | disc_loss: -0.06317351013422012 | gen_loss: 0.5878883004188538\n",
            "compute_gradients\n",
            "Epoch: 461 | disc_loss: -0.08078987896442413 | gen_loss: 0.5885050296783447\n",
            "compute_gradients\n",
            "Epoch: 462 | disc_loss: -0.05325130373239517 | gen_loss: 0.5865902900695801\n",
            "compute_gradients\n",
            "Epoch: 463 | disc_loss: -0.06911899894475937 | gen_loss: 0.5880311727523804\n",
            "compute_gradients\n",
            "Epoch: 464 | disc_loss: -0.05478593707084656 | gen_loss: 0.5884696841239929\n",
            "compute_gradients\n",
            "Epoch: 465 | disc_loss: -0.0717158317565918 | gen_loss: 0.5920390486717224\n",
            "compute_gradients\n",
            "Epoch: 466 | disc_loss: 0.01245240867137909 | gen_loss: 0.5895800590515137\n",
            "compute_gradients\n",
            "Epoch: 467 | disc_loss: -0.06636879593133926 | gen_loss: 0.5896617770195007\n",
            "compute_gradients\n",
            "Epoch: 468 | disc_loss: -0.06838128715753555 | gen_loss: 0.5903481245040894\n",
            "compute_gradients\n",
            "Epoch: 469 | disc_loss: -0.0636909157037735 | gen_loss: 0.5883212685585022\n",
            "compute_gradients\n",
            "Epoch: 470 | disc_loss: -0.05946025997400284 | gen_loss: 0.5903452038764954\n",
            "compute_gradients\n",
            "Epoch: 471 | disc_loss: -0.07330945879220963 | gen_loss: 0.5911208987236023\n",
            "compute_gradients\n",
            "Epoch: 472 | disc_loss: -0.07021288573741913 | gen_loss: 0.59056556224823\n",
            "compute_gradients\n",
            "Epoch: 473 | disc_loss: -0.06215331703424454 | gen_loss: 0.590080738067627\n",
            "compute_gradients\n",
            "Epoch: 474 | disc_loss: -0.06457466632127762 | gen_loss: 0.5897350907325745\n",
            "compute_gradients\n",
            "Epoch: 475 | disc_loss: -0.05696801096200943 | gen_loss: 0.5879441499710083\n",
            "compute_gradients\n",
            "Epoch: 476 | disc_loss: -0.07555678486824036 | gen_loss: 0.5923929810523987\n",
            "compute_gradients\n",
            "Epoch: 477 | disc_loss: -0.06092505902051926 | gen_loss: 0.5882217288017273\n",
            "compute_gradients\n",
            "Epoch: 478 | disc_loss: -0.0528411827981472 | gen_loss: 0.5892505049705505\n",
            "compute_gradients\n",
            "Epoch: 479 | disc_loss: -0.0730070173740387 | gen_loss: 0.5880873203277588\n",
            "compute_gradients\n",
            "Epoch: 480 | disc_loss: -0.07072816789150238 | gen_loss: 0.5909841060638428\n",
            "compute_gradients\n",
            "Epoch: 481 | disc_loss: -0.05982065200805664 | gen_loss: 0.588782548904419\n",
            "compute_gradients\n",
            "Epoch: 482 | disc_loss: -0.06650755554437637 | gen_loss: 0.5892022848129272\n",
            "compute_gradients\n",
            "Epoch: 483 | disc_loss: -0.06996627151966095 | gen_loss: 0.5901896953582764\n",
            "compute_gradients\n",
            "Epoch: 484 | disc_loss: -0.05540285259485245 | gen_loss: 0.5881691575050354\n",
            "compute_gradients\n",
            "Epoch: 485 | disc_loss: -0.07053091377019882 | gen_loss: 0.5906916260719299\n",
            "compute_gradients\n",
            "Epoch: 486 | disc_loss: -0.0581623874604702 | gen_loss: 0.5901103019714355\n",
            "compute_gradients\n",
            "Epoch: 487 | disc_loss: -0.07920639961957932 | gen_loss: 0.5923112034797668\n",
            "compute_gradients\n",
            "Epoch: 488 | disc_loss: -0.04605097323656082 | gen_loss: 0.5885815620422363\n",
            "compute_gradients\n",
            "Epoch: 489 | disc_loss: -0.06825435161590576 | gen_loss: 0.5899485349655151\n",
            "compute_gradients\n",
            "Epoch: 490 | disc_loss: -0.07705916464328766 | gen_loss: 0.5900201797485352\n",
            "compute_gradients\n",
            "Epoch: 491 | disc_loss: -0.056384965777397156 | gen_loss: 0.5927053093910217\n",
            "compute_gradients\n",
            "Epoch: 492 | disc_loss: -0.07033094763755798 | gen_loss: 0.5903750658035278\n",
            "compute_gradients\n",
            "Epoch: 493 | disc_loss: -0.06241217628121376 | gen_loss: 0.5898082256317139\n",
            "compute_gradients\n",
            "Epoch: 494 | disc_loss: -0.0673721581697464 | gen_loss: 0.5904572010040283\n",
            "compute_gradients\n",
            "Epoch: 495 | disc_loss: -0.053757455199956894 | gen_loss: 0.5894162654876709\n",
            "compute_gradients\n",
            "Epoch: 496 | disc_loss: -0.06810816377401352 | gen_loss: 0.5909631252288818\n",
            "compute_gradients\n",
            "Epoch: 497 | disc_loss: -0.05258950591087341 | gen_loss: 0.5885577201843262\n",
            "compute_gradients\n",
            "Epoch: 498 | disc_loss: -0.06472368538379669 | gen_loss: 0.5919728875160217\n",
            "compute_gradients\n",
            "Epoch: 499 | disc_loss: -0.028196822851896286 | gen_loss: 0.5911015272140503\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-14T06:46:24.425722Z",
          "start_time": "2019-05-14T06:46:24.188266Z"
        },
        "colab_type": "code",
        "id": "XZbwB70ESYcH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "6f2e7f8d-ccca-4c4d-952b-1383ff1841ba"
      },
      "source": [
        "plt.plot(losses.gen_loss.values)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f6b20f4d0f0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD7CAYAAABt0P8jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlVLKx2jgV0opH6OBXymlfMz/A9Wut9z7JU9mAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-14T06:46:38.649136Z",
          "start_time": "2019-05-14T06:46:38.440378Z"
        },
        "colab_type": "code",
        "id": "FydTnKDxSYcL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "b6fb4667-d18c-42be-a003-a2fa486264ce"
      },
      "source": [
        "plt.plot(losses.disc_loss.values)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f6b20a0a4a8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWsAAAD7CAYAAACsV7WPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcIzLZj5Seh9",
        "colab_type": "text"
      },
      "source": [
        "#### Encoder GAN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JPQP0vvCja5o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1b3af2c4-53d2-4d06-9bd1-1939d38b162b"
      },
      "source": [
        "x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32) \n",
        "x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "epsilon = tf.random.uniform([x.shape[0], 1, 1, 1], 0.0, 1.0)\n",
        "print(epsilon.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 1, 1, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3m0fQ6OXgPf1",
        "colab_type": "text"
      },
      "source": [
        "# GAN Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4FU2Q7yh0OU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_encoding(M=16, n=1):\n",
        "    inp = np.arange(0,M)\n",
        "    coding = gan_encoder.predict(inp)\n",
        "    fig = plt.figure(figsize=(4,4))\n",
        "    plt.plot(coding[:,0], coding[:, 1], \"b.\")\n",
        "    plt.xlabel(\"$x_1$\", fontsize=18)\n",
        "    plt.ylabel(\"$x_2$\", fontsize=18, rotation=0)\n",
        "    plt.grid(True)\n",
        "    plt.gca().set_ylim(-2, 2)\n",
        "    plt.gca().set_xlim(-2, 2)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def Test_AE(data):\n",
        "    '''Calculate Bit Error for varying SNRs'''\n",
        "    snr_range = np.linspace(0, 15, 31)\n",
        "    bber_vec = [None] * len(snr_range)\n",
        "        \n",
        "    for db in range(len(snr_range)):           \n",
        "        noise_std = EbNo_to_noise(snr_range[db])\n",
        "        code_word = gan_encoder(data)\n",
        "        rcvd_word = real_channel(code_word,noise_std)\n",
        "        dcoded_msg = gan_decoder(rcvd_word)\n",
        "        bber_vec[db] = B_Ber_m(data, dcoded_msg)\n",
        "        if (db % 6 == 0) & (db > 0):\n",
        "            print(f'Progress: {db} of {30} parts')\n",
        "\n",
        "    return (snr_range, bber_vec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GW2opX7SwMo",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# AE training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNHtzAC4SPBq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_gan_encoder(M):\n",
        "  model = keras.models.Sequential([\n",
        "            keras.layers.Embedding(M, M, embeddings_initializer='glorot_normal'),\n",
        "            keras.layers.Dense(M, activation=\"elu\"),\n",
        "            keras.layers.Dense(n, activation=None),\n",
        "            e2,\n",
        "            EncOut,\n",
        "            GenIn])\n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5KjEhDvSWQR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_gan_decoder(M):\n",
        "   model= keras.models.Sequential([\n",
        "                #DecIn,\n",
        "                #d1,\n",
        "                keras.layers.Dense(M, activation=\"elu\"),\n",
        "                keras.layers.Dense(M, activation=\"softmax\")\n",
        "                ])\n",
        "   return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PB4rw6Qhtdbe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w_generator.trainable =False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiuN3SZYpeTU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "outputId": "b5bb2ca5-6a1e-4d3b-d552-9f6ea9fc2f88"
      },
      "source": [
        "#%%time\n",
        "gan_decoder = get_gan_decoder(M)\n",
        "gan_encoder = get_gan_encoder(M)\n",
        "\n",
        "gan_AE = tf.keras.models.Sequential([gan_encoder,w_generator,gan_decoder])\n",
        "data, test_data = random_sample(1000000), random_sample(1000)\n",
        "start = time.time()\n",
        "gan_AE.compile(optimizer=keras.optimizers.Nadam(lr=0.005),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "history = gan_AE.fit(data, data, batch_size=400,steps_per_epoch=200, epochs=6)\n",
        "#time_to_train_gan += time.time()-start\n",
        "#tf.print ('Time for the training is {} sec,'.format( time.time()-start))\n",
        "gan_AE.summary()  "
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "200/200 [==============================] - 318s 2s/step - loss: 2.2247 - accuracy: 0.2422\n",
            "Epoch 2/6\n",
            "200/200 [==============================] - 317s 2s/step - loss: 1.6494 - accuracy: 0.4948\n",
            "Epoch 3/6\n",
            "200/200 [==============================] - 317s 2s/step - loss: 1.3536 - accuracy: 0.6408\n",
            "Epoch 4/6\n",
            "200/200 [==============================] - 317s 2s/step - loss: 1.1087 - accuracy: 0.7658\n",
            "Epoch 5/6\n",
            "200/200 [==============================] - 317s 2s/step - loss: 0.8200 - accuracy: 0.8445\n",
            "Epoch 6/6\n",
            "200/200 [==============================] - 316s 2s/step - loss: 0.5232 - accuracy: 0.9359\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential_3 (Sequential)    (None, None)              562       \n",
            "_________________________________________________________________\n",
            "sequential (Sequential)      (None, 2)                 1218      \n",
            "_________________________________________________________________\n",
            "sequential_2 (Sequential)    (None, 16)                320       \n",
            "=================================================================\n",
            "Total params: 2,100\n",
            "Trainable params: 882\n",
            "Non-trainable params: 1,218\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngrucnfWBOHl",
        "colab_type": "text"
      },
      "source": [
        "### Training MI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5B2TUanPC5d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "1d074823-ec52-49ae-fd31-e8a20423d62c"
      },
      "source": [
        "gan_encoder.trainable = False\n",
        "gan_decoder.trainable = False\n",
        "\n",
        "test_encoding(M,n)   \n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAASMAAAEWCAYAAAAtl/EzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukO76l6yIoPc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test msg sequence for normal encoding\n",
        "N_test = 500000\n",
        "test_msg = np.random.randint(M, size=N_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5iCDE4dSL35",
        "colab_type": "text"
      },
      "source": [
        "#### decoder GAN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7M-S0sbhIoPw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "f3cd1918-1261-4253-c90f-9d516ba1faf8"
      },
      "source": [
        "gan_bber_data = Test_AE(test_msg)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Progress: 6 of 30 parts\n",
            "Progress: 12 of 30 parts\n",
            "Progress: 18 of 30 parts\n",
            "Progress: 24 of 30 parts\n",
            "Progress: 30 of 30 parts\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYdEm0eQIoP2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "outputId": "004fd159-e76c-41a7-de43-531bef382ebb"
      },
      "source": [
        "# Approximate 16 QAM Error\n",
        "def SIXT_QAM_sim(ebno):\n",
        "    return (3.0/2)*special.erfc(np.sqrt((4.0/10)*10.**(ebno/10)))\n",
        "\n",
        "ebnodbs = np.linspace(0,15,16)\n",
        "fig = plt.figure(figsize=(8, 5))\n",
        "plt.semilogy(gan_bber_data[0], gan_bber_data[1], '^-')\n",
        "plt.semilogy(ebnodbs, SIXT_QAM_sim(ebnodbs), '*-');\n",
        "plt.gca().set_ylim(1e-5, 1)\n",
        "plt.gca().set_xlim(0, 15)\n",
        "plt.ylabel(\"Batch Symbol Error Rate\", fontsize=14, rotation=90)\n",
        "plt.xlabel(\"SNR [dB]\", fontsize=18)\n",
        "plt.legend(['AE with WGAN', '16QAM'],\n",
        "           prop={'size': 14}, loc='upper right');\n",
        "plt.grid(True, which=\"both\")\n",
        "\n",
        "#print('time to train the AE Model with MI',time_to_train_mi)\n",
        "#print('time to train the AE Model with GAN',time_to_train_gan)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAFPCAYAAADQqc3dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBes21qLlcS8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f5fe4838-b9e9-4fef-c602-e77fc8188c6a"
      },
      "source": [
        "print(range(11))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "range(0, 11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuvTdY-IfWvx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}